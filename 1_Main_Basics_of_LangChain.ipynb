{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03bd1e6",
   "metadata": {},
   "source": [
    "# THE BASICS OF LANGCHAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cdda8",
   "metadata": {},
   "source": [
    "## Setting LangChain up\n",
    "The first thing we have to do is make sure we have LangChain installed in our environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e657391",
   "metadata": {},
   "source": [
    "### Installing LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492a3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacd2f9",
   "metadata": {},
   "source": [
    "# Defining our OpenAI API Key\n",
    "Utilizing LangChain typically means integrating with diverse model providers, data stores, APIs, among other components. In this case we want to use OpenAI's GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338f9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfc64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054137e",
   "metadata": {},
   "source": [
    "## LLM - Calling a model with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948b02d",
   "metadata": {},
   "source": [
    "### OpenAI - GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef4e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KDnuggets is a rewards program that allows users to earn rewards for doing the best work. There are a variety of rewards that can be earned, including points, likes, shares, and be part of a community.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\")\n",
    "print(llm(\"Explain me briefly whta's KDnuggets!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b4e15",
   "metadata": {},
   "source": [
    "### HuggingFace - Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a3219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KDnuggets is a website that provides information about data science, machine learning,\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "HF_API_KEY=\"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\"\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-v0.1\", huggingfacehub_api_token=HF_API_KEY)\n",
    "print(llm(\"Explain me briefly whta's KDnuggets!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107825b",
   "metadata": {},
   "source": [
    "### Switching between LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ff832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT LLM: \n",
      "\n",
      "A KDnuggets is a piece of software that helps you save money on groceries. It does this by reducing the cost of your groceries by 50%. \n",
      "\n",
      "HF-Mistral LLM: \n",
      "\n",
      "KDnuggets is a website that provides information about data science, machine learning,\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI, HuggingFaceHub\n",
    "\n",
    "prompt = \"Explain me briefly what's KDnuggets!\"\n",
    "\n",
    "gpt   = OpenAI(model_name=\"text-ada-001\")\n",
    "mistral = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-v0.1\", huggingfacehub_api_token=HF_API_KEY)\n",
    "\n",
    "print(\"GPT LLM:\", gpt(prompt), \"\\n\\nHF-Mistral LLM:\", mistral(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ec828",
   "metadata": {},
   "source": [
    "### Asking multiple prompts at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5872583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm.generate([\n",
    "    \n",
    "    \"Explain me briefly what's KDnuggets!\",\n",
    "\n",
    "    \"How can I become part of KDnuggets\",\n",
    "\n",
    "    \"Should I read KDnuggets?\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6eaa7",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eaaf9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Output: {\n",
      "Product: \"Samsung washing machine\",\n",
      "Satisfaction: False,\n",
      "Reason: \"Too expensive for what it is\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review  = \"\"\"\n",
    "\n",
    "I bought last week the latest Samsung washing machine. \n",
    "The product is too expensive for what it is. \n",
    "I won't recommend it to anyone.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "template = \"\"\" \n",
    "\n",
    "For any new review that is sent to you, extract the following information:\n",
    "\n",
    "Product: What product is the buyer reviewing?\\\n",
    "Answer the name of the product. If this information is not found, output unknown.\n",
    "\n",
    "Reason why: Why's the buyer satisfied or unsatisfied?\n",
    "Answer the main reason why. Answer unknown if you do not find the info. \n",
    "\n",
    "Satisfied: Is the buyer satisfied with the product? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "Product\n",
    "Satisfaction\n",
    "Reason\n",
    "\n",
    "review: {review}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "\n",
    "input_variables=[\"review\"],\n",
    "\n",
    "template=template,\n",
    "\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(review=review )\n",
    "\n",
    "print(f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d5c64",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9e083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_name': 'Samsung washing machine',\n",
       " 'satisfaction': 'Unsatisfied',\n",
       " 'reason': 'Too expensive for what it is'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "response_schemas = [\n",
    "    \n",
    "    ResponseSchema(name=\"product_name\", description=\"Answer the name of the product.\"),\n",
    "    ResponseSchema(name=\"satisfaction\", description=\"Answer if the buyer is Satisfied or Unsatisfied.\"),\n",
    "    ResponseSchema(name=\"reason\",       description=\"Answer the reason why the buyer is satisfied or unsatisfied.\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "template = \"\"\" \n",
    "You are a review checker specialist. You main goal is to extract worth information from any review that is sent to you. \n",
    "From the following review {review}, extract the following information:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"review\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "model = OpenAI(temperature=0)\n",
    "_input = prompt.format_prompt(review=review)\n",
    "output = model(_input.to_string())\n",
    "output_json = output_parser.parse(output)\n",
    "output_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
